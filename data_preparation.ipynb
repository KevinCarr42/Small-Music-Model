{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13ea9d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a5635ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import chord progressions and tokens\n",
    "chord_progressions = pd.read_pickle('df_clean.pickle').rename({'chord_progression_C':'chords'}, axis=1)[['chords']]\n",
    "chord_progressions['chords'] = chord_progressions['chords'].apply(lambda x: x + ['<EOS>'])\n",
    "\n",
    "# remove progressions that aren't at least a minimum length\n",
    "min_progression_length = 2\n",
    "chord_progressions = chord_progressions[chord_progressions['chords'].str.len()>min_progression_length].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa16e13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4630 unique chord progressions out of 17302 total chord progressions'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many different chord progressions do we have?\n",
    "f\"{chord_progressions.chords.astype('str').nunique()} unique chord progressions out of {chord_progressions.shape[0]} total chord progressions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6458616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chords\n",
       "['Am', 'F', 'C', 'G', '<EOS>']    433\n",
       "['C', 'G', 'Am', 'F', '<EOS>']    426\n",
       "['F', 'C', 'G', '<EOS>']          318\n",
       "['F', 'C', 'G', 'Am', '<EOS>']    244\n",
       "['C', 'F', '<EOS>']               224\n",
       "['G', 'F', 'C', '<EOS>']          205\n",
       "['F', 'G', 'C', '<EOS>']          202\n",
       "['C', 'G', 'F', '<EOS>']          196\n",
       "['C', 'G', '<EOS>']               170\n",
       "['G', 'Am', 'F', 'C', '<EOS>']    170\n",
       "['C', 'F', 'G', '<EOS>']          162\n",
       "['F', 'G', 'Am', '<EOS>']         159\n",
       "['Am', 'G', 'F', '<EOS>']         157\n",
       "['Am', 'F', 'C', '<EOS>']         150\n",
       "['Am', 'F', 'G', '<EOS>']         148\n",
       "['C', 'Am', 'F', 'G', '<EOS>']    139\n",
       "['C', 'Am', 'F', '<EOS>']         128\n",
       "['F', 'Am', 'G', '<EOS>']         117\n",
       "['G', 'C', 'F', '<EOS>']          109\n",
       "['Dm', 'F', 'C', 'G', '<EOS>']     91\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most common chord progressions\n",
    "chord_progressions.chords.astype('str').value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80916168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0\t        \t<EOS>   \tAm      \tAm/E    \tAm/F    \tAm11    \tAm6     \t\n",
      "Am7     \tAm7/C   \tAm7/G   \tAm7add11\tAm9     \tAmadd9  \tAmaj7   \tAmaj7sus2\t\n",
      "Amaj9   \tAmmaj7  \tBm      \tBm11    \tBm6     \tBm7     \tBm7b5   \tBm9     \t\n",
      "Bmaj7   \tBmmaj7  \tC       \tC/E     \tC/G     \tC2      \tC4      \tC5      \t\n",
      "C6      \tC6add11 \tC7      \tC7add11 \tC7sus2  \tC7sus4  \tC9      \tCadd#11 \t\n",
      "Cadd11  \tCadd2   \tCadd4   \tCadd9   \tCaug    \tCflat5  \tCsus    \tCsus2   \t\n",
      "Csus4   \tDdim    \tDm      \tDm11    \tDm13    \tDm6     \tDm6/F   \tDm7     \t\n",
      "Dm7/G   \tDm7add11\tDm7b5   \tDm9     \tDmadd9  \tDmaj    \tDmaj7   \tDmaj9   \t\n",
      "E       \tE5      \tE6      \tE7      \tE7b13   \tE7b9    \tE7sus   \tE7sus4  \t\n",
      "E9sus4  \tEdim    \tEm      \tEm6     \tEm7     \tEm9     \tEmadd9  \tEmaj7   \t\n",
      "Esus2   \tEsus4   \tF       \tF/G     \tF2      \tF5      \tF6      \tF6add9  \t\n",
      "F6sus2  \tF7      \tF7sus4  \tF9      \tF9b5    \tFadd#11 \tFadd2   \tFadd4   \t\n",
      "Fadd9   \tFflat5  \tFsus    \tFsus2   \tFsus4   \tG       \tG#m     \tG#m7    \t\n",
      "G#maj7  \tG/C     \tG11     \tG13     \tG2      \tG4      \tG5      \tG6      \t\n",
      "G6add11 \tG6sus2  \tG7      \tG7b9    \tG7sus   \tG7sus2  \tG7sus4  \tG9      \t\n",
      "Gadd11  \tGadd4   \tGadd4add9\tGadd9   \tGaug    \tGsus    \tGsus2   \tGsus4   \t\n",
      "\n",
      "\n",
      "Number of Tokens:  128\n"
     ]
    }
   ],
   "source": [
    "# what are all of the chords (tokens)?\n",
    "tokens = set(' ')  # include the space between chords as a token\n",
    "for _, row in chord_progressions.iterrows():\n",
    "    tokens |= set(row.chords)\n",
    "tokens = [0] + sorted(list(tokens))  # include zero for zero padding\n",
    "\n",
    "# encoder / decoder\n",
    "encoder = dict()\n",
    "idx = 0\n",
    "for token in tokens:\n",
    "    encoder[token] = idx\n",
    "    idx += 1\n",
    "\n",
    "# save to file\n",
    "with open('tokens.pickle', 'wb') as f:\n",
    "    pickle.dump(tokens, f)\n",
    "with open('encoder.pickle', 'wb') as f:\n",
    "    pickle.dump(encoder, f)\n",
    "    \n",
    "# examine tokens\n",
    "i = 0\n",
    "for token in tokens:\n",
    "    print(f'{token:8}', end='\\t')\n",
    "    i += 1\n",
    "    if i%8 == 0:\n",
    "        print()     \n",
    "print('\\n')\n",
    "print('Number of Tokens: ', len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9eca5fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training validation split\n",
    "val_size = 0.1\n",
    "train, val = train_test_split(chord_progressions, test_size=val_size)\n",
    "\n",
    "# max chords in progression -> sequence_length\n",
    "sequence_length = pd.read_pickle('df_clean.pickle')['chord_progression_C'].str.len().max()\n",
    "\n",
    "# add to list, zero pad if required\n",
    "def get_progression_list(progressions_df, zero_pad=False):\n",
    "    prog_list, prog_list_enc = list(), list()\n",
    "    for _, progression in progressions_df.iterrows():\n",
    "        x = progression.values[0]  # list of chords\n",
    "        if zero_pad:  # zero pad\n",
    "            x = x + [0]*(sequence_length - len(x))\n",
    "        y = list()  # encoded list of chords\n",
    "        for chord in x:\n",
    "            y.append(encoder[chord])\n",
    "        prog_list += x\n",
    "        prog_list_enc += y\n",
    "    return prog_list, prog_list_enc\n",
    "    \n",
    "train_list, train_list_enc = get_progression_list(train)\n",
    "val_list, val_list_enc = get_progression_list(val)\n",
    "\n",
    "# save to file as np.array\n",
    "train_enc = np.array(train_list_enc, dtype=np.uint16)\n",
    "train_enc.tofile('train.bin')\n",
    "val_enc = np.array(val_list_enc, dtype=np.uint16)\n",
    "val_enc.tofile('val.bin')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
